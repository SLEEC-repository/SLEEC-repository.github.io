---
layout: default
title: Case Study
---

<nav>
  <ul class="left-navbar">
    <li class="left-navbar-item"><a class="left-navbar-link" href="#description">Description</a></li>
    <li class="left-navbar-item"><a class="left-navbar-link" href="#characteristics">Characteristics</a></li>
    <li class="left-navbar-item"><a class="left-navbar-link" href="#normative-requirements">Normative<br />Requirements</a></li>
    <li class="left-navbar-item"><a class="left-navbar-link" href="#formalised-requirements">Formalised<br />Requirements</a></li>
  </ul>
</nav>

<div class="case-study-sections-container">
  <main class="case-study-sections">
    <section class="case-study-description" id="description">
      
      <p>With a rapidly ageing population, the world is facing a social care crisis (Appleby, 2009). Without a step change in the provision of social care, especially to the elderly, the increase in the budgets and resources allocated to social care will soon become unsustainable. Ambient assisted living (Blackman et al., 2016) (i.e., assisted living support provided in a person’s daily environment, with the aid of robotic and autonomous systems – RAS, Artificial Intelligence – AI, and other technologies) is widely envisaged as a key component of such a step change (Lee et al., 2018).
        <br /><br />
        Given this vision, the development of assisted-living RAS and AI solutions has been the focus of intense research and industrial effort in recent years. Designed to help or even replace carers at home and in care homes, these solutions aim to support people with motor or cognitive impairments in a wide range of tasks, increasing their ability to pursue daily living activities independently. These advances have provided RAS solutions capable of assisting elderly and disabled users both in a monitoring/advisory role and with physical tasks. However, integrating the two types of assistance into a combined assistive-care RAS solution that can be used safely over a long period of time still poses significant challenges (SPARK, 2015).
        <br /><br />
        In the ALMI project, we employ a TIAGo robot that uses both its speech interaction and its object manipulation capabilities to help a user with mild motor and cognitive impairments in the daily activity of preparing a meal. Specifically, the TIAGo robot (i) provides step-by-step voice instructions guiding the user through the meal preparation task; (ii) fetches and hands to the user some of the food ingredients, kitchen utensils, crockery, etc. required for these steps; (iii) reminds the user (if needed) where to find other items that are required for the task, and that the robot cannot reach or handle. Providing such support requires the robot to dynamically create, update and exploit a “knowledge store” of household item locations (over a long period of time); to track the user’s progress with the meal preparation task, so that instructions are delivered progressively and repeated if necessary; to handle disruptions safely, etc.
        <br /><br />
        The safe handling of disruptions requires the robot to react to events such as task interruptions due to a phone call received by the user, or loss of vision due to the light being switched off accidentally by the user, or as a result of a power cut. If such unexpected events interrupt the execution of the task, the robot will mitigate the detrimental effects of interruption (if there are remedial actions that can be performed), or issue an alert when an unsafe situation cannot be handled directly by using its capabilities.
        <br /><br />
        TIAGo is a highly customisable mobile robotic platform with 15 degrees of freedom (DoF). The TIAGo robot comprises a mobile base with a footprint of 54cm, an adjustable height torso enabling the robot to vary its overall height between 110–140cm, a pan-tilt head, and a 7 DoF manipulator arm with a reach of 87cm and a payload of 3kg. The mobile base is provided with a differential drive capable of speeds of up to 1 m/s, and uses a LIDAR laser for indoor navigation. The TIAGo control software and applications are deployed on an Intel i7 (7th generation) computer with 16 GB of RAM, 500 GB of disk space, and running Ubuntu LTS 64-bit with the RT Preempt real-time framework. Multiple ROS LTS controllers running in a real-time control loop are used to manage robot components including its torso, head and arm positions, with joint trajectory controllers used from groups of joints and a Head Action Server for controlling the robot’s gaze. The TIAGo navigation unit supports laser-based mapping and self-location, with obstacle avoidance and navigation to map point capabilities. The upper-body motion engine controllers support path planning with self-collision avoidance, and come with a wide range of pre-programmed motions and facilities for defining customised motions. Particularly relevant for ALMI, TIAGo supports (i) speech-based interaction with the users through its integrated ACAPELA<sup>1</sup> text to-speech system and DeepSpeech<sup>2</sup> speech-to-text module; (ii) object and people detection thanks to its ASUS XTION Pro Live 3D Camera mounted on the robot’s head.
        <br /><br />
        Appleby, J. Spending on health and social care over the next 50 years. Why think long term?, 2013. The King’s Fund. 4. M. W. Bewernitz, W. C. Mann, P. Dasler, and P. Belchior. Feasibility of machine-based prompting to assist persons with dementia. Assistive Technology, 21(4):196–207, 2009.
        <br /><br />
        Blackman, S., Matlo, C., Bobrovitskiy, C., Waldoch, A., Fang, M L.,  Jackson, P., Mihailidis, A., Nygard, L., Astell, A., and Sixsmith, A. Ambient assisted living technologies for aging well: a scoping review. Journal of Intelligent Systems, 25(1):55–69, 2016
        <br /><br />
        Lee H R. and Riek L D. Reframing assistive robots to promote successful aging. ACM Transactions on Human-Robot Interaction (THRI), 7(1):1–23, 2018.
        <br /><br />
        SPARC – The Partnership for Robotics in Europe. Robotics 2020 multi-annual roadmap for robotics in Europe, 2015.</p></section>
    <section id="characteristics">
      <h2>Stage of Development</h2>
      <p>Deployed, SIMULATION, MODELLING</p>
      <h2>Expert info</h2>
      <p>Expertise of the stakeholders involved in devising the SLEEC rules
        Number of stakeholders writing the rules
        <br /><br />
        [Table]
      </p>
      <h2>Main functionality and purpose</h2>
      <p>In the ALMI project, we harness the PAL Robotics framework, TIAGo, and evolve it into an array of social robotic solutions. TIAGo employs both its voice interaction for audio commands and its object manipulation skills to assist a user with mild motor and cognitive impairments in the everyday task of meal preparation. Moreover, TIAGo is equipped with the essential manipulation capabilities and assurance evidence for the customized robotic arm, and it also possesses environment monitoring capabilities to establish and maintain a knowledgebase of objects.
        <br /><br />
        Whenever disruptive changes occur (for example, when the user abandons a task), TIAGo adapts both its configuration and behaviour to achieve task completion, or to gracefully degrade, preserving safety even if the task is not successfully completed. To achieve this, we developed methods for the synthesis of adaptation plans for the robotic platform. Determining the course for adaptation in our experimental environment entails securing a safe combination of robot configuration and task plan specification for the robot’s execution context.
        <br /><br />
        PAL Robotics constructed the first prototype of a novel robotic arm featuring new sensors and capabilities to adhere to the standards of industrial and personal care robotics. Cutting-edge electronics and actuators have been applied that allowed it to implement more advanced control functions (e.g, force control).Together with the application of brakes, they improved the security features of the TIAGo arm to be able to collaborate closely with humans. The new arm complies with the expected levels of security and robustness. The capabilities of this new arm are tailored for applications involving human-robot interaction. On the one hand, the torque sensing and Ethercat bus allow for superior low-level closed-loop torque control. This allows the full control of the arm in effort mode, which makes the arm compliant. Namely, the control architecture can be modified at a low level by emulating a spring at the joint level, and this permits to use the robot exactly as it was used before, but with this new compliant feature, and not losing any accuracy. All standard robot movements can now be performed safely so that any potential collisions, either with the robot or any external entity, would not harm the human or the robot. On the other hand, there are breaks also at joint level. In the case there was any misuse of the robot, or even the emergency stop was activated, the arm would not fall but maintain position. Hence, as a direct consequence of these two features of the arm, a layer in safety of the interaction between machine and human has been added, without losing any of the previous capabilities of the robot.
        <br /><br />
        TIAGo is also capable of generating a semantic map of an apartment, learning about an object or location, and executing general-purpose tasks as instructed by a user through its human-robot interaction, navigation, and robot-object interaction abilities. The TIAGo knowledge repository consists of a semantic map of the user's surroundings, with the positions of objects specified at particular sites. This semantic map is formulated using the existing ROS (The Robot Operating System) Navigation Stack functionality, after mapping the user's environment and/or inputting the details. The semantic map is devised to be as reusable as possible with custom types of objects with various attributes, thereby enabling TIAGo to hold a variety of household items like furniture, utensils, and meal preparation ingredients. This approach is embodied in a customised middleware that captures and processes information broadcasted to ROS topics, incorporating it into a knowledge store containing the domain models needed for validation and adaptation.
        <h2>Normative requirements</h2>
        <div class="toggle-switch">
          <input type="checkbox" id="toggle" class="toggle-input">
          <label for="toggle" class="toggle-label">
            <span class="toggle-text">Before</span>
            <span class="toggle-text">After</span>
          </label>
        </div>
      </p>
    </section>
    <section id="normative-requirements">Normative Requirements</section>
    <section id="formalised-requirements">Formalised Requirements</section>
  </main>

  <script src="/assets/js/left-navbar.js"></script>
</div>
